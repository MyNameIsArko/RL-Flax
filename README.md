<div align="center">
    <img src="https://github.com/MyNameIsArko/RL-Flax/assets/47687092/6886a474-8e6a-4953-9b81-3f67b6a8da68" alt="logo">
</div>

# RL-Flax
This is an attempt to recreate many reinforcement learning algorithms in Jax(Flax) world as single-file implementations.
## Run Locally

Clone the project

```bash
  git clone https://github.com/MyNameIsArko/RL-Flax
```

Go to the project directory

```bash
  cd RL-Flax
```

Install dependencies

```bash
  pip install "jax[cuda]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
  pip install flax tensorflow-probability
```

Run the notebook you want!


## Roadmap

- DQN

- Rainbow DQN

- A2C

- A3C


## Contributing

Any kind of contribution is welcome!

If you know a little bit of Jax+Flax and know ins and outs of some algorithm then make a pull request. I'll gladly accept it as this is a big project for one man.
## Acknowledgements
 - [PPO implementation details](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)
 - [CleanRL](https://github.com/vwxyzjn/cleanrl)
 - [Jax documentation](https://jax.readthedocs.io/en/latest/)
 - [Flax documentation](https://github.com/matiassingers/awesome-readme)
 - [Tfp documentation](https://www.tensorflow.org/probability/api_docs/python/tfp/substrates/jax)


## License

[MIT](https://choosealicense.com/licenses/mit/)

